{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoB8zubzhVhJ"
      },
      "source": [
        "# Simple MNIST convnet\n",
        "🧩 Step 1: Importing NumPy\n",
        "import numpy as np\n",
        "👩‍🏫 Ask your students:\n",
        "“Why do you think we need NumPy in a deep learning project?”\n",
        "🧠 Explain:\n",
        "NumPy is the foundation of numerical computing in Python.\n",
        "Keras (and TensorFlow) internally use NumPy arrays to handle image pixels, labels, and features.\n",
        "💬 Analogy:\n",
        "“Think of NumPy as the calculator brain — it helps Python handle large tables of numbers super fast.”\n",
        "🧮 Example:\n",
        "•\tImages are stored as 2D or 3D arrays.\n",
        "•\tNumPy helps us reshape, normalize, or preprocess them.\n",
        "________________________________________\n",
        "⚙️ Step 2: Importing Keras\n",
        "import keras\n",
        "👩‍🏫 Ask:\n",
        "“What is Keras? A library, a framework, or a model?”\n",
        "🧠 Explain:\n",
        "Keras is a high-level deep learning API built on top of TensorFlow.\n",
        "It allows you to build, train, and test neural networks easily — with just a few lines of code.\n",
        "💬 Analogy:\n",
        "“If TensorFlow is a powerful engine, Keras is the smooth car dashboard that lets you drive it easily!”\n",
        "💡 Fun fact:\n",
        "Before, you had to write dozens of lines in TensorFlow to build a model.\n",
        "With Keras → just a few lines.\n",
        "________________________________________\n",
        "🧱 Step 3: Importing Layers\n",
        "from keras import layers\n",
        "👩‍🏫 Ask:\n",
        "“What do you think these layers are for?”\n",
        "🧠 Explain:\n",
        "Every neural network is made up of layers — each performs a specific job:\n",
        "•\tConv2D: Extracts image features\n",
        "•\tMaxPooling2D: Reduces size\n",
        "•\tFlatten: Converts 2D to 1D\n",
        "•\tDense: Makes final decisions (classification)\n",
        "•\tDropout: Prevents overfitting\n",
        "💬 Analogy:\n",
        "“Think of layers as steps in a factory assembly line —\n",
        "each one transforms the raw material (image) a little bit until it becomes the final product (prediction).”\n",
        "________________________________________\n",
        "🎯 Summary for Bootcamp Recap\n",
        "Import\tPurpose\tAnalogy\n",
        "numpy\tHandles numeric data and image arrays\tCalculator brain 🧮\n",
        "keras\tFramework to build neural networks\tCar dashboard 🚗\n",
        "keras.layers\tBuilding blocks of the neural net\tFactory steps 🏭\n",
        "________________________________________\n",
        "Would you like me to add a simple visual diagram (showing how “image data → NumPy → Keras → Layers → Model” flows) that you can include in your teaching slides?\n",
        "Perfect 👍 Let’s turn this into an interactive and fun explanation you can use during your bootcamp training session — so your juniors don’t just hear it, they actually understand it.\n",
        "________________________________________\n",
        "🧩 Step-by-step Interactive Explanation\n",
        "🎯 Step 1: Model / Data Parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "👩‍🏫 Ask students:\n",
        "\"Can anyone guess why num_classes is 10?\"\n",
        "🧠 Explain:\n",
        "Because the MNIST dataset has 10 classes — digits 0 to 9.\n",
        "Each image is a handwritten number.\n",
        "\"And what about (28, 28, 1) — why do we have that extra 1?\"\n",
        "💡 Answer:\n",
        "•\t28 x 28 = image size (pixels).\n",
        "•\t1 = grayscale channel (since MNIST images are black & white).\n",
        "If it were a color image, it would be (28, 28, 3) for RGB.\n",
        "________________________________________\n",
        "🪄 Step 2: Loading the Dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "👩‍🏫 Ask:\n",
        "\"Who knows what happens when this line runs?\"\n",
        "🧠 Explain:\n",
        "Keras automatically downloads and loads the MNIST dataset for you!\n",
        "It gives you:\n",
        "•\tx_train: training images\n",
        "•\ty_train: correct digit labels for training\n",
        "•\tx_test and y_test: for testing the model later\n",
        "\"In short — this one line saves us hours of data collection!\"\n",
        "________________________________________\n",
        "🌈 Step 3: Normalizing (Scaling) Images\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "👩‍🏫 Ask:\n",
        "\"Why do we divide by 255?\"\n",
        "🧠 Explain:\n",
        "Each pixel’s intensity ranges from 0 to 255.\n",
        "Dividing by 255 converts it to 0–1, making it easier for the neural network to learn.\n",
        "(It trains faster and avoids large number errors.)\n",
        "\"Think of it like normalizing marks from 0–100 to 0–1 — easier to compare!\"\n",
        "________________________________________\n",
        "🧱 Step 4: Adding the Channel Dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "👩‍🏫 Ask:\n",
        "\"Why are we adding one more dimension?\"\n",
        "🧠 Explain:\n",
        "Originally, x_train shape is (60000, 28, 28) → just height and width.\n",
        "But CNNs expect input like (height, width, channels).\n",
        "So we add that 1 channel for grayscale using np.expand_dims.\n",
        "Result:\n",
        "(60000, 28, 28, 1) — ✅ perfect for CNNs.\n",
        "________________________________________\n",
        "📊 Step 5: Checking Data Shapes\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "👩‍🏫 Explain with enthusiasm:\n",
        "“Always check your data shapes before modeling — it’s like checking ingredients before cooking!”\n",
        "Output:\n",
        "x_train shape: (60000, 28, 28, 1)\n",
        "60000 train samples\n",
        "10000 test samples\n",
        "So we have 60,000 handwritten digits for training and 10,000 for testing.\n",
        "________________________________________\n",
        "🧮 Step 6: Converting Labels to One-Hot Encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "👩‍🏫 Ask:\n",
        "\"What do you think this line does? Why not just use numbers 0–9?\"\n",
        "🧠 Explain:\n",
        "Neural networks work better when each class is represented as a vector, not just a number.\n",
        "Example:\n",
        "Digit 3 → [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "Digit 7 → [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "This is called One-Hot Encoding 🔥\n",
        "It helps the network treat all classes equally instead of “closer” numbers (like 8 being near 9).\n",
        "________________________________________\n",
        "🎓 Wrap-Up Summary (Quick Recap for Students)\n",
        "Step\tPurpose\n",
        "1️⃣ Set Parameters\tDefine classes and image shape\n",
        "2️⃣ Load Data\tGet MNIST dataset\n",
        "3️⃣ Normalize\tScale pixels 0–1\n",
        "4️⃣ Expand Dims\tAdd channel for CNN\n",
        "5️⃣ Print Shapes\tVerify data size\n",
        "6️⃣ One-Hot Encode\tConvert labels for classification\n",
        "________________________________________\n",
        "Would you like me to create a short slide-style version (with emojis & visuals) of this same explanation — perfect for showing during your bootcamp?\n",
        "Excellent 👏 — this is the heart of your CNN model, and it’s perfect for explaining in an interactive, visual way during your bootcamp session.\n",
        "Let’s break it down step-by-step so your juniors feel how each layer transforms the image — like a story unfolding! 🎬\n",
        "________________________________________\n",
        "🧠 Step-by-Step Interactive Explanation\n",
        "🧩 Step 1: The Model\n",
        "model = keras.Sequential([...])\n",
        "👩‍🏫 Say to your students:\n",
        "\"Imagine you’re building a sandwich — one layer at a time.\n",
        "That’s exactly what Sequential means! Each layer is stacked in order, and the output of one becomes the input of the next.\"\n",
        "________________________________________\n",
        "🧱 Step 2: Input Layer\n",
        "keras.Input(shape=input_shape)\n",
        "🧠 Explain:\n",
        "This defines the shape of each input image — (28, 28, 1) = height, width, and grayscale channel.\n",
        "💬 Analogy:\n",
        "“This is like telling the model — ‘Hey, every image you’ll see is 28x28 pixels and black & white!’”\n",
        "________________________________________\n",
        "🎨 Step 3: First Convolutional Layer\n",
        "layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")\n",
        "🧠 Explain interactively:\n",
        "\"Think of this layer as 32 small scanners (filters) sliding over the image — each trying to detect different patterns like edges, curves, or corners.\"\n",
        "•\t32 → number of filters (features the model will learn)\n",
        "•\t(3, 3) → size of each filter (like a small 3x3 window)\n",
        "•\tReLU → removes negative values → keeps only useful signals\n",
        "💬 Analogy:\n",
        "“It’s like shining 32 tiny flashlights on different parts of the image to detect unique features.”\n",
        "________________________________________\n",
        "🌀 Step 4: First Pooling Layer\n",
        "layers.MaxPooling2D(pool_size=(2, 2))\n",
        "🧠 Explain:\n",
        "This layer shrinks the image while keeping the important parts.\n",
        "•\tTakes a 2×2 patch → picks the maximum value\n",
        "•\tReduces computation and helps the model focus on key patterns\n",
        "💬 Analogy:\n",
        "“Think of it like zooming out of a photo — you lose some detail, but you still recognize what’s important.”\n",
        "________________________________________\n",
        "🎨 Step 5: Second Convolutional Layer\n",
        "layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\")\n",
        "🧠 Explain:\n",
        "Now the model learns more complex patterns using 64 filters.\n",
        "After the first layer learned simple edges, this one can detect shapes, loops, or digit structures.\n",
        "💬 Analogy:\n",
        "“The model is now learning to recognize numbers, not just lines — like a student going from alphabets to words.”\n",
        "________________________________________\n",
        "🌀 Step 6: Second Pooling Layer\n",
        "layers.MaxPooling2D(pool_size=(2, 2))\n",
        "🧠 Explain:\n",
        "Again reduces the size, keeping only essential patterns.\n",
        "Now the image is small, but contains deep, meaningful information.\n",
        "________________________________________\n",
        "🧾 Step 7: Flatten Layer\n",
        "layers.Flatten()\n",
        "🧠 Explain:\n",
        "This takes the 2D feature maps and flattens them into a 1D vector.\n",
        "💬 Analogy:\n",
        "“Imagine you’re unrolling a 2D carpet into a straight line — we’re preparing the features for the fully connected layer.”\n",
        "________________________________________\n",
        "💧 Step 8: Dropout Layer\n",
        "layers.Dropout(0.5)\n",
        "🧠 Explain:\n",
        "This randomly “turns off” 50% of neurons during training to prevent overfitting.\n",
        "💬 Ask students:\n",
        "“Why would we want to drop neurons?”\n",
        "✅ To make sure the model doesn’t memorize the training data and can generalize better.\n",
        "💬 Analogy:\n",
        "“It’s like forcing students to study without always relying on the same notes — helps them truly understand.”\n",
        "________________________________________\n",
        "🧠 Step 9: Output Layer\n",
        "layers.Dense(num_classes, activation=\"softmax\")\n",
        "🧠 Explain:\n",
        "•\tDense = fully connected layer (every neuron connects to every output)\n",
        "•\tnum_classes = 10 (digits 0–9)\n",
        "•\tSoftmax → converts outputs into probabilities (like: 80% chance of being “3”, 15% chance of being “5”, etc.)\n",
        "💬 Analogy:\n",
        "“The model is now guessing the number — like saying ‘I’m 90% sure this is a 7!’”\n",
        "________________________________________\n",
        "🧾 Step 10: Model Summary\n",
        "model.summary()\n",
        "🧠 Explain:\n",
        "Shows the architecture, output shapes, and parameters for each layer —\n",
        "like a blueprint of your model.\n",
        "💬 Analogy:\n",
        "“It’s the report card of your model — you can see how data flows through every layer.”\n",
        "________________________________________\n",
        "🌟 Final Visualization (You Can Say This)\n",
        "🗣️\n",
        "“So our model first detects edges, then shapes, then digits.\n",
        "It keeps simplifying and learning — from pixels to patterns to predictions.\n",
        "Just like our brains learn to read handwriting!”\n",
        "________________________________________\n",
        "Would you like me to make a diagram (simple CNN architecture flow with images → filters → pooling → flatten → dense → output) that you can show during your session?\n",
        "Perfect 😎 — now we’re at the training stage, where your model finally learns from the data!\n",
        "Let’s make this super interactive and visual so your juniors enjoy the bootcamp while truly understanding what’s happening behind the code.\n",
        "________________________________________\n",
        "🚀 Step-by-Step Interactive Explanation\n",
        "⚙️ Step 1: Setting Hyperparameters\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "👩‍🏫 Ask your students:\n",
        "“What do you think batch_size means? And what about epochs?”\n",
        "🧠 Explain in simple terms:\n",
        "•\tBatch size (128):\n",
        "The model doesn’t look at all 60,000 images at once (that’s too heavy!).\n",
        "Instead, it studies 128 images at a time, learns from them, updates weights, and repeats.\n",
        "💬 Analogy:\n",
        "“Think of it like studying in small groups instead of the entire class at once.”\n",
        "•\tEpochs (15):\n",
        "One epoch = the model has seen all training images once.\n",
        "So, with 15 epochs, it studies the dataset 15 times, improving its understanding each round.\n",
        "💬 Analogy:\n",
        "“Like rereading your notes 15 times — you understand better with every pass!”\n",
        "________________________________________\n",
        "🧠 Step 2: Compiling the Model\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "👩‍🏫 Ask:\n",
        "“Why do we need to compile before training?”\n",
        "🧠 Explain:\n",
        "This tells the model how to learn — like giving instructions before starting a class.\n",
        "•\tloss=\"categorical_crossentropy\"\n",
        "→ This measures how wrong the model’s predictions are (for multi-class classification).\n",
        "The model tries to minimize this loss.\n",
        "💬 Analogy:\n",
        "“It’s like checking how many questions you got wrong in a test — the goal is to minimize mistakes.”\n",
        "•\toptimizer=\"adam\"\n",
        "→ Adam is a smart algorithm that updates weights automatically and efficiently.\n",
        "It helps the model converge (learn fast and accurately).\n",
        "💬 Analogy:\n",
        "“Adam is like an intelligent coach — it adjusts your learning rate dynamically.”\n",
        "•\tmetrics=[\"accuracy\"]\n",
        "→ We track accuracy during training — how many predictions are correct.\n",
        "________________________________________\n",
        "🏋️ Step 3: Training the Model\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "👩‍🏫 Ask:\n",
        "“What do you think happens when we call fit()?”\n",
        "🧠 Explain:\n",
        "This is where the real training happens.\n",
        "•\tThe model takes input images, predicts outputs, compares them with the correct labels (y_train),\n",
        "and updates itself to reduce the loss — over and over again.\n",
        "•\tvalidation_split=0.1 means:\n",
        "10% of training data is kept aside for validation (to check how well the model generalizes while learning).\n",
        "💬 Analogy:\n",
        "“Imagine you study 90% of your syllabus and keep 10% aside for self-testing.\n",
        "That’s what validation does — checks how you’re doing during the process!”\n",
        "________________________________________\n",
        "📊 Step 4: What You’ll See on Screen\n",
        "When you run model.fit, you’ll see something like this:\n",
        "Epoch 1/15\n",
        "422/422 [==============================] - 10s 23ms/step - loss: 0.3502 - accuracy: 0.8960 - val_loss: 0.0921 - val_accuracy: 0.9723\n",
        "🧠 Explain how to read it:\n",
        "•\tEpoch 1/15 → You’re on the first round of training.\n",
        "•\tloss: Model’s error on training data.\n",
        "•\taccuracy: Correct predictions on training data.\n",
        "•\tval_loss / val_accuracy: Performance on validation data (unseen during training).\n",
        "💬 Analogy:\n",
        "“It’s like seeing your progress after every practice test — both how you do on your notes (train) and on sample papers (validation).”\n",
        "________________________________________\n",
        "🎓 Wrap-Up Summary Table\n",
        "Term\tMeaning\tAnalogy\n",
        "batch_size\tNumber of samples processed before updating weights\tStudy in small groups\n",
        "epoch\tOne full pass through training data\tOne full study cycle\n",
        "loss\tHow wrong the model is\tNumber of wrong answers\n",
        "optimizer\tHow the model learns\tLearning strategy / teacher\n",
        "validation_split\tPortion for testing while training\tSelf-assessment test\n",
        "________________________________________\n",
        "Would you like me to create an animated-style diagram showing how data moves through batches → epochs → training → validation (like a mini training loop visualization) that you can use in your bootcamp slides?\n",
        "Excellent 🌟 — you’ve now reached the evaluation phase, where your model’s learning is tested on new, unseen data!\n",
        "Let’s make this step interactive and engaging so your juniors can visualize what’s really happening here. 👇\n",
        "________________________________________\n",
        "🧠 Step-by-Step Interactive Explanation\n",
        "🧪 Step 1: Evaluating the Model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "👩‍🏫 Ask your students:\n",
        "“So, we trained the model on training data — but how do we know if it really understands digits and isn’t just memorizing them?”\n",
        "🧠 Explain:\n",
        "That’s exactly what model.evaluate() does.\n",
        "It checks how well the model performs on test data — data it has never seen before.\n",
        "💬 Analogy:\n",
        "“Imagine you’ve been practicing math problems for days (training),\n",
        "and now the teacher gives you a final exam with new questions (testing).\n",
        "evaluate() is your scorecard!”\n",
        "________________________________________\n",
        "⚙️ Step 2: What Happens Inside model.evaluate()\n",
        "The function:\n",
        "•\tFeeds the test images (x_test) into the model.\n",
        "•\tCompares the predicted labels with the true labels (y_test).\n",
        "•\tCalculates the final loss and accuracy.\n",
        "verbose=0 just hides progress output (you can use 1 to show it).\n",
        "________________________________________\n",
        "🧾 Step 3: Printing the Results\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "🧠 Explain:\n",
        "•\tscore[0] → Test loss\n",
        "Measures how much error the model still makes on unseen data.\n",
        "➤ Lower = better\n",
        "•\tscore[1] → Test accuracy\n",
        "Tells what percentage of images the model classified correctly.\n",
        "➤ Closer to 1 (or 100%) = better\n",
        "💬 Analogy:\n",
        "“Loss is like the number of mistakes you made,\n",
        "and accuracy is how many answers you got right on your final test.”\n",
        "________________________________________\n",
        "📊 Step 4: Example Output\n",
        "Test loss: 0.045\n",
        "Test accuracy: 0.985\n",
        "🎉 Interpretation:\n",
        "“Our model got 98.5% accuracy on unseen digits —\n",
        "which means it can correctly recognize most handwritten numbers!”\n",
        "________________________________________\n",
        "💬 Interactive Q&A Ideas for Bootcamp\n",
        "Here are some questions you can throw at your juniors to keep it lively:\n",
        "1.\t🧩 What’s the difference between training accuracy and test accuracy?\n",
        "→ (Training accuracy shows how well the model performs on known data, test accuracy shows generalization.)\n",
        "2.\t🔥 Why is test accuracy usually a bit lower than training accuracy?\n",
        "→ (Because the model might slightly overfit to the training data.)\n",
        "3.\t🎯 If the loss is low but accuracy isn’t high, what does that tell you?\n",
        "→ (Model might be confused on certain classes or not well-calibrated.)\n",
        "________________________________________\n",
        "🎓 Wrap-Up Summary\n",
        "Concept\tDescription\tAnalogy\n",
        "evaluate()\tTests model on unseen data\tFinal exam\n",
        "Test loss\tHow wrong predictions are\tNumber of mistakes\n",
        "Test accuracy\tPercentage of correct predictions\tScore out of 100\n",
        "Goal\tLow loss, high accuracy\tSmart + confident model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Description:** A simple convnet that achieves ~99% test accuracy on MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqEch3mIhVhL"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Every neural network is made up of layers — each performs a specific job:\n",
        "•\tConv2D: Extracts image features\n",
        "•\tMaxPooling2D: Reduces size\n",
        "•\tFlatten: Converts 2D to 1D\n",
        "•\tDense: Makes final decisions (classification)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ibxO_FgqjIP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weP1dF4IhVhM"
      },
      "outputs": [],
      "source": [
        "import numpy as np   #  numerical computation eg.Handle image pixels ,labels, and features\n",
        "import keras        # build train,test neural networks\n",
        "from keras import layers  # building blocks of neural net i.e. Conv2D ,MaxPooling,Flatten,Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0aLJrv2hVhN"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\" why num_classes is 10?\"\n",
        "🧠 Explain:\n",
        "Because the MNIST dataset has 10 classes — digits 0 to 9.\n",
        "Each image is a handwritten number.\n",
        "\"And what about (28, 28, 1) — why do we have that extra 1?\"\n",
        "💡 Answer:\n",
        "•\t28 x 28 = image size (pixels).\n",
        "•\t1 = grayscale channel (since MNIST images are black & white).\n",
        "If it were a color image, it would be (28, 28, 3) for RGB.\n"
      ],
      "metadata": {
        "id": "Ub0m7Oa4lC9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)"
      ],
      "metadata": {
        "id": "iSAdQeGQkw7n"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras automatically downloads and loads the MNIST dataset for you!\n",
        "It gives you:\n",
        "•\tx_train: training images\n",
        "•\ty_train: correct digit labels for training\n",
        "•\tx_test and y_test: for testing the model later\n"
      ],
      "metadata": {
        "id": "25MXlzzglvdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "Slkj3SyRlt_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mCXQSNX5mQss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Why do we divide by 255?\"\n",
        "\n",
        "🧠 Explain:\n",
        "Each pixel’s intensity ranges from 0 to 255.\n",
        "Dividing by 255 converts it to 0–1, making it easier for the neural network to learn.\n",
        "(It trains faster and avoids large number errors.)\n",
        "\n",
        "\"Think of it like normalizing marks from 0–100 to 0–1 — easier to compare!\"\n"
      ],
      "metadata": {
        "id": "AhLiNIXNmTr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") /255"
      ],
      "metadata": {
        "id": "-dm180WAmPO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding the Channel Dimension **\n",
        "\n",
        "\n",
        "\"Why are we adding one more dimension?\"\n",
        "🧠 Explain:\n",
        "\n",
        "Originally, x_train shape is (60000, 28, 28) → just height and width.\n",
        "But CNNs expect input like (height, width, channels).\n",
        "\n",
        "So we add that 1 channel for grayscale using np.expand_dims.\n"
      ],
      "metadata": {
        "id": "Rzsg0gqsmwX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)"
      ],
      "metadata": {
        "id": "ixbRBKWSmuvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiAbLz32hVhN"
      },
      "outputs": [],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Data Shapes**"
      ],
      "metadata": {
        "id": "UBJ1pOWSn_YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n"
      ],
      "metadata": {
        "id": "Rdlj2BAnn9kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting Labels to One-Hot Encoding**\n",
        "\n",
        "Neural networks work better when each class is represented as a vector, not just a number.\n",
        "Example:\n",
        "Digit 3 → [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "Digit 7 → [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "\n",
        "\n",
        "This is called One-Hot Encoding 🔥\n",
        "\n",
        "It helps the network treat all classes equally instead of “closer” numbers (like 8 being near 9).\n"
      ],
      "metadata": {
        "id": "ruHPzetDoVVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "jQfCwHBuoMYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moHC0LGChVhO"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model = keras.Sequential([...])\n",
        "\n",
        "That’s exactly what Sequential means!\n",
        "\n",
        "Each layer is stacked in order, and the output of one becomes the input of the next.\n",
        "\n",
        "keras.Input(shape=input_shape)\n",
        "🧠 Explain:\n",
        "\n",
        "This defines the shape of each input image — (28, 28, 1) = height, width, and grayscale channel.\n",
        "\n",
        "💬 Analogy:\n",
        "“This is like telling the model —\n",
        "\n",
        "‘Hey, every image you’ll see is 28x28 pixels and black & white!’”\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jakQmVkXo07F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnTwix31hVhO"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abTsc1yshVhP"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1HAKliZhVhP"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UodAXCXhhVhQ"
      },
      "source": [
        "## Evaluate the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOQ83KyAhVhQ"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mnist_convnet",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}